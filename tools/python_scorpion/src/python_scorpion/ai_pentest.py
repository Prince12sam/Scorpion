"""python_scorpion.ai_pentest

AI-assisted security assessment orchestration.

This module is intentionally designed for authorized, defensive security work:
- discovery
- analysis
- reporting

It does NOT provide exploit/payload generation, reverse shells, or instructions
for unauthorized access.
"""

from __future__ import annotations

import asyncio
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

import httpx


class AIProvider:
    """Minimal async client for AI text generation.

    Used by:
    - `scorpion code-scan --ai-summary`

    This client is restricted to defensive usage (remediation guidance).
    """

    def __init__(
        self,
        provider: str,
        api_key: str,
        model: str,
        endpoint: Optional[str] = None,
        timeout_s: float = 60.0,
    ) -> None:
        self.provider = (provider or "").strip().lower()
        self.api_key = api_key
        self.model = model
        self.endpoint = endpoint
        self.client = httpx.AsyncClient(timeout=timeout_s)

    async def query(self, system_prompt: str, user_prompt: str, temperature: float = 0.2) -> str:
        if self.provider in {"openai", "github", "custom"}:
            url = (self.endpoint or "https://api.openai.com/v1/chat/completions").rstrip("/")
            payload = {
                "model": self.model,
                "temperature": float(temperature),
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            }
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            }
            resp = await self.client.post(url, json=payload, headers=headers)
            resp.raise_for_status()
            data = resp.json()
            choices = data.get("choices") or []
            if not choices:
                return ""
            msg = choices[0].get("message") or {}
            return str(msg.get("content") or "").strip()

        if self.provider == "anthropic":
            url = (self.endpoint or "https://api.anthropic.com/v1/messages").rstrip("/")
            payload = {
                "model": self.model,
                "max_tokens": 800,
                "temperature": float(temperature),
                "system": system_prompt,
                "messages": [{"role": "user", "content": user_prompt}],
            }
            headers = {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            }
            resp = await self.client.post(url, json=payload, headers=headers)
            resp.raise_for_status()
            data = resp.json()
            content = data.get("content") or []
            if not content:
                return ""
            # Anthropic returns a list of blocks.
            first = content[0] or {}
            return str(first.get("text") or "").strip()

        raise ValueError(f"Unsupported AI provider: {self.provider}")


class PrimaryGoal(str, Enum):
    COMPREHENSIVE = "comprehensive_assessment"
    VULN_DISCOVERY = "vulnerability_discovery"
    NETWORK_MAPPING = "network_mapping"
    INFRASTRUCTURE = "infrastructure_assessment"
    CLOUD_SECURITY = "cloud_security_audit"
    API_SECURITY = "api_security_testing"
    COMPLIANCE_REVIEW = "compliance_review"


class AutonomyLevel(str, Enum):
    SUPERVISED = "supervised"  # Ask confirmation before each action
    SEMI_AUTONOMOUS = "semi_autonomous"  # Ask before high-risk actions
    FULLY_AUTONOMOUS = "fully_autonomous"  # Executes without confirmation


class StealthLevel(str, Enum):
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"


class RiskTolerance(str, Enum):
    LOW = "low"  # Passive/safe
    MEDIUM = "medium"  # Active scanning
    HIGH = "high"  # Most active scanning (still no exploitation)


class EngagementPolicy(str, Enum):
    SAFE = "safe"
    STANDARD = "standard"
    AGGRESSIVE = "aggressive"
    EXTREME = "extreme"


@dataclass
class AIPentestConfig:
    target: str
    primary_goal: PrimaryGoal = PrimaryGoal.COMPREHENSIVE
    secondary_goals: List[str] = None  # type: ignore[assignment]

    time_limit: int = 120
    max_iterations: int = 20

    stealth_level: StealthLevel = StealthLevel.MODERATE
    autonomy_level: AutonomyLevel = AutonomyLevel.SEMI_AUTONOMOUS
    risk_tolerance: RiskTolerance = RiskTolerance.MEDIUM
    engagement_policy: EngagementPolicy = EngagementPolicy.STANDARD

    ai_provider: str = "openai"
    model: str = "gpt-4"
    api_key: Optional[str] = None
    api_endpoint: Optional[str] = None

    learning_mode: bool = False
    custom_instructions: Optional[str] = None

    def __post_init__(self) -> None:
        if self.secondary_goals is None:
            self.secondary_goals = []


class AIPentestAgent:
    """Orchestrates defensive assessment actions.

    The intent is to provide a single report object that the CLI can render.
    The implementation is conservative and focuses on compatibility and safety.
    """

    def __init__(self, config: AIPentestConfig) -> None:
        self.config = config

    async def execute(self) -> Dict[str, Any]:
        start = datetime.now(timezone.utc)

        # Import locally to keep module import lightweight and to reduce circulars.
        findings: List[Dict[str, Any]] = []
        actions: List[Dict[str, Any]] = []

        # Always include a minimal safety/authorization reminder.
        actions.append(
            {
                "type": "notice",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "detail": "Run only against systems you own or have explicit written authorization to test.",
            }
        )

        # Best-effort: tech fingerprinting and passive OWASP checks if available.
        try:
            from .tech import detect_tech

            actions.append(
                {
                    "type": "tech_fingerprint",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "detail": "Detecting technology stack (best-effort)",
                }
            )
            tech = detect_tech(self.config.target)
            findings.append(
                {
                    "type": "tech",
                    "severity": "info",
                    "confidence": 70,
                    "details": tech,
                }
            )
        except Exception as exc:
            actions.append(
                {
                    "type": "tech_fingerprint",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "detail": f"Skipped/failed tech detection: {exc}",
                }
            )

        if self.config.primary_goal in {
            PrimaryGoal.COMPREHENSIVE,
            PrimaryGoal.VULN_DISCOVERY,
            PrimaryGoal.API_SECURITY,
        }:
            try:
                from .web_owasp import web_owasp_passive

                actions.append(
                    {
                        "type": "web_owasp_passive",
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "detail": "Running passive OWASP checks (best-effort)",
                    }
                )
                owasp = await web_owasp_passive(self.config.target)
                findings.append(
                    {
                        "type": "web_owasp_passive",
                        "severity": "info",
                        "confidence": 60,
                        "details": owasp,
                    }
                )
            except Exception as exc:
                actions.append(
                    {
                        "type": "web_owasp_passive",
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "detail": f"Skipped/failed OWASP passive checks: {exc}",
                    }
                )

        end = datetime.now(timezone.utc)
        duration_minutes = max(0.0, (end - start).total_seconds() / 60.0)

        findings_by_severity = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        for f in findings:
            sev = str(f.get("severity", "info")).lower()
            if sev in findings_by_severity:
                findings_by_severity[sev] += 1
            else:
                findings_by_severity["info"] += 1

        report: Dict[str, Any] = {
            "summary": {
                "target": self.config.target,
                "start_time": start.isoformat(),
                "end_time": end.isoformat(),
                "duration_minutes": round(duration_minutes, 2),
                "iterations": 1,
                "total_findings": len(findings),
                "total_actions": len(actions),
                "primary_goal": self.config.primary_goal.value,
                "stealth_level": self.config.stealth_level.value,
                "risk_tolerance": self.config.risk_tolerance.value,
                "engagement_policy": self.config.engagement_policy.value,
            },
            "config": asdict(self.config),
            "actions": actions,
            "findings_by_severity": findings_by_severity,
            "detailed_findings": findings,
            "recommendations": [
                "Prioritize fixes for authentication/authorization issues and exposed secrets.",
                "Add security headers and enforce TLS best practices.",
                "Enable centralized logging + alerting for suspicious behavior.",
            ],
        }

        return report


def run(config: AIPentestConfig) -> Dict[str, Any]:
    """Convenience wrapper used by other modules."""

    return asyncio.run(AIPentestAgent(config).execute())
