"""python_scorpion.ai_pentest

AI-assisted security assessment orchestration.

This module is intentionally designed for authorized, defensive security work:
- discovery
- analysis
- reporting

It does NOT provide exploit/payload generation, reverse shells, or instructions
for unauthorized access.
"""

from __future__ import annotations

import asyncio
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import httpx


class AIProvider:
    """Minimal async client for AI text generation.

    Used by:
    - `scorpion code-scan --ai-summary`

    This client is restricted to defensive usage (remediation guidance).
    """

    def __init__(
        self,
        provider: str,
        api_key: str,
        model: str,
        endpoint: Optional[str] = None,
        timeout_s: float = 60.0,
    ) -> None:
        self.provider = (provider or "").strip().lower()
        self.api_key = api_key
        self.model = model
        self.endpoint = endpoint
        self.client = httpx.AsyncClient(timeout=timeout_s)

    async def query(self, system_prompt: str, user_prompt: str, temperature: float = 0.2) -> str:
        if self.provider in {"openai", "github", "custom"}:
            url = (self.endpoint or "https://api.openai.com/v1/chat/completions").rstrip("/")
            payload = {
                "model": self.model,
                "temperature": float(temperature),
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
            }
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            }
            resp = await self.client.post(url, json=payload, headers=headers)
            resp.raise_for_status()
            data = resp.json()
            choices = data.get("choices") or []
            if not choices:
                return ""
            msg = choices[0].get("message") or {}
            return str(msg.get("content") or "").strip()

        if self.provider == "anthropic":
            url = (self.endpoint or "https://api.anthropic.com/v1/messages").rstrip("/")
            payload = {
                "model": self.model,
                "max_tokens": 800,
                "temperature": float(temperature),
                "system": system_prompt,
                "messages": [{"role": "user", "content": user_prompt}],
            }
            headers = {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            }
            resp = await self.client.post(url, json=payload, headers=headers)
            resp.raise_for_status()
            data = resp.json()
            content = data.get("content") or []
            if not content:
                return ""
            # Anthropic returns a list of blocks.
            first = content[0] or {}
            return str(first.get("text") or "").strip()

        raise ValueError(f"Unsupported AI provider: {self.provider}")


class PrimaryGoal(str, Enum):
    COMPREHENSIVE = "comprehensive_assessment"
    VULN_DISCOVERY = "vulnerability_discovery"
    NETWORK_MAPPING = "network_mapping"
    INFRASTRUCTURE = "infrastructure_assessment"
    CLOUD_SECURITY = "cloud_security_audit"
    API_SECURITY = "api_security_testing"
    COMPLIANCE_REVIEW = "compliance_review"


class AutonomyLevel(str, Enum):
    SUPERVISED = "supervised"  # Ask confirmation before each action
    SEMI_AUTONOMOUS = "semi_autonomous"  # Ask before high-risk actions
    FULLY_AUTONOMOUS = "fully_autonomous"  # Executes without confirmation


class StealthLevel(str, Enum):
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"


class RiskTolerance(str, Enum):
    LOW = "low"  # Passive/safe
    MEDIUM = "medium"  # Active scanning
    HIGH = "high"  # Most active scanning (still no exploitation)


class EngagementPolicy(str, Enum):
    SAFE = "safe"
    STANDARD = "standard"
    AGGRESSIVE = "aggressive"
    EXTREME = "extreme"


@dataclass
class AIPentestConfig:
    target: str
    primary_goal: PrimaryGoal = PrimaryGoal.COMPREHENSIVE
    secondary_goals: List[str] = None  # type: ignore[assignment]

    time_limit: int = 120
    max_iterations: int = 20

    stealth_level: StealthLevel = StealthLevel.MODERATE
    autonomy_level: AutonomyLevel = AutonomyLevel.SEMI_AUTONOMOUS
    risk_tolerance: RiskTolerance = RiskTolerance.MEDIUM
    engagement_policy: EngagementPolicy = EngagementPolicy.STANDARD

    ai_provider: str = "openai"
    model: str = "gpt-4"
    api_key: Optional[str] = None
    api_endpoint: Optional[str] = None

    learning_mode: bool = False
    custom_instructions: Optional[str] = None

    def __post_init__(self) -> None:
        if self.secondary_goals is None:
            self.secondary_goals = []


class AIPentestAgent:
    """Orchestrates defensive assessment actions.

    The intent is to provide a single report object that the CLI can render.
    The implementation is conservative and focuses on compatibility and safety.
    """

    def __init__(self, config: AIPentestConfig) -> None:
        self.config = config

    async def execute(self) -> Dict[str, Any]:
        start = datetime.now(timezone.utc)
        deadline = start.timestamp() + float(max(1, int(self.config.time_limit))) * 60.0

        findings: List[Dict[str, Any]] = []
        actions: List[Dict[str, Any]] = []
        evidence: Dict[str, Any] = {}
        seen_findings: set[str] = set()

        def _now() -> str:
            return datetime.now(timezone.utc).isoformat()

        def _normalize_severity(sev: str) -> str:
            s = (sev or "info").strip().lower()
            if s in {"critical", "high", "medium", "low", "info"}:
                return s
            return "info"

        def _add_action(action_type: str, detail: str, status: str = "ok", extra: Optional[Dict[str, Any]] = None) -> None:
            item: Dict[str, Any] = {
                "type": action_type,
                "timestamp": _now(),
                "detail": detail,
                "status": status,
            }
            if extra:
                item.update(extra)
            actions.append(item)

        def _add_finding(
            *,
            severity: str,
            tool: str,
            category: str,
            description: str,
            recommended_action: str,
            evidence_obj: Optional[Dict[str, Any]] = None,
            remediation: Optional[str] = None,
            confidence: int = 60,
            tags: Optional[List[str]] = None,
        ) -> None:
            normalized = {
                "timestamp": _now(),
                "severity": _normalize_severity(severity),
                "tool": tool,
                "category": category,
                "description": description,
                "recommended_action": recommended_action,
                "remediation": remediation or "",
                "confidence": int(max(0, min(100, confidence))),
                "evidence": evidence_obj or {},
                "tags": tags or [],
            }
            # Dedupe across iterations. Avoid hashing full evidence (can be large/noisy).
            dedupe_key = str(
                {
                    "severity": normalized["severity"],
                    "tool": normalized["tool"],
                    "category": normalized["category"],
                    "description": normalized["description"],
                    "remediation": normalized["remediation"],
                }
            )
            if dedupe_key in seen_findings:
                return
            seen_findings.add(dedupe_key)
            findings.append(normalized)

        def _parse_target(raw: str) -> Dict[str, Any]:
            raw = (raw or "").strip()
            if raw.startswith("http://") or raw.startswith("https://"):
                p = urlparse(raw)
                scheme = p.scheme or "https"
                hostname = p.hostname or raw
                port = p.port
            else:
                p = urlparse(f"https://{raw}")
                scheme = "https"
                hostname = p.hostname or raw
                port = p.port
            host_with_port = hostname + (f":{port}" if port else "")
            return {
                "raw": raw,
                "scheme": scheme,
                "hostname": hostname,
                "port": port,
                "host_with_port": host_with_port,
            }

        def _can_do_active() -> bool:
            return self.config.risk_tolerance in {RiskTolerance.MEDIUM, RiskTolerance.HIGH}

        def _can_do_aggressive_api() -> bool:
            return (
                self.config.risk_tolerance == RiskTolerance.HIGH
                and self.config.engagement_policy in {EngagementPolicy.AGGRESSIVE, EngagementPolicy.EXTREME}
            )

        def _stealth_profile() -> Dict[str, Any]:
            if self.config.stealth_level == StealthLevel.HIGH:
                return {
                    "scan_timeout": 2.5,
                    "scan_concurrency": 60,
                    "dir_concurrency": 10,
                    "dir_limit": 120,
                }
            if self.config.stealth_level == StealthLevel.MODERATE:
                return {
                    "scan_timeout": 1.5,
                    "scan_concurrency": 150,
                    "dir_concurrency": 20,
                    "dir_limit": 200,
                }
            return {
                "scan_timeout": 1.0,
                "scan_concurrency": 250,
                "dir_concurrency": 35,
                "dir_limit": 300,
            }

        def _ports_for_profile() -> List[int]:
            # Keep deterministic ordering.
            # Medium: small but high-signal list. High: broader common list.
            base = [
                21,
                22,
                23,
                25,
                53,
                80,
                110,
                135,
                139,
                143,
                443,
                445,
                465,
                587,
                993,
                995,
                1433,
                1521,
                2049,
                2375,
                2376,
                3000,
                3306,
                3389,
                4000,
                4443,
                5000,
                5001,
                5432,
                5672,
                5985,
                5986,
                6379,
                7001,
                7199,
                8000,
                8008,
                8080,
                8081,
                8088,
                8181,
                8443,
                8888,
                9000,
                9090,
                9200,
                9300,
                9443,
                10000,
                10250,
                11211,
                15672,
                27017,
            ]

            if self.config.risk_tolerance == RiskTolerance.MEDIUM:
                return [p for p in base if p in {22, 80, 443, 445, 3389, 8080, 8443, 3306, 5432, 6379, 9200, 27017}]

            # HIGH: broaden signal without going full 1-65535 by default.
            return base

        _add_action(
            "notice",
            "Run only against systems you own or have explicit written authorization to test.",
        )

        target = _parse_target(self.config.target)
        evidence["target"] = target

        ai: Optional[AIProvider] = None
        if self.config.api_key:
            try:
                ai = AIProvider(
                    provider=self.config.ai_provider,
                    api_key=self.config.api_key,
                    model=self.config.model,
                    endpoint=self.config.api_endpoint,
                    timeout_s=60.0,
                )
            except Exception as exc:
                _add_action("ai_init", f"AI provider init failed: {exc}", status="error")
                ai = None
        else:
            _add_action("ai_init", "No AI key provided; running in non-AI mode", status="skipped")

        profile = _stealth_profile()

        async def _run_passive_bundle() -> None:
            tasks: List[asyncio.Task] = []

            async def _tech() -> None:
                try:
                    from .tech import detect_tech

                    _add_action("tech_fingerprint", "Detecting technology stack (best-effort)")
                    tech = await detect_tech(target["host_with_port"])
                    evidence["tech"] = tech
                    _add_finding(
                        severity="info",
                        tool="tech",
                        category="fingerprint",
                        description="Technology fingerprint collected",
                        recommended_action="Use detected stack to prioritize targeted configuration and dependency checks",
                        evidence_obj={"tech": tech},
                        confidence=70,
                        tags=["fingerprint"],
                    )
                except Exception as exc:
                    _add_action("tech_fingerprint", f"Tech detection failed: {exc}", status="error")

            async def _recon() -> None:
                try:
                    from .recon import recon

                    _add_action("recon", "Collecting DNS/WHOIS/HTTP header hints (best-effort)")
                    r = await recon(target["hostname"])
                    evidence["recon"] = r
                    for f in r.get("findings", []) or []:
                        _add_finding(
                            severity=f.get("severity", "info"),
                            tool="recon",
                            category=str(f.get("type") or "recon"),
                            description=str(f.get("impact") or "Recon hint"),
                            recommended_action="Adjust scanning strategy to account for WAF/CDN and validate with allowlisting if authorized",
                            remediation=str(f.get("remediation") or ""),
                            evidence_obj={"location": f.get("location"), "details": f},
                            confidence=60,
                            tags=["recon"],
                        )
                except Exception as exc:
                    _add_action("recon", f"Recon failed: {exc}", status="error")

            async def _ssl() -> None:
                try:
                    from .ssl_analyzer import analyze_ssl

                    ssl_port = int(target["port"] or 443)
                    _add_action("ssl_analyze", f"Analyzing TLS and security headers (port {ssl_port})")
                    s = await analyze_ssl(target["hostname"], port=ssl_port)
                    evidence["ssl"] = s
                    sev = _normalize_severity(str(s.get("severity") or "info"))
                    remediation_list = s.get("remediation") or []
                    remediation_text = "; ".join([str(x) for x in remediation_list]) if isinstance(remediation_list, list) else str(remediation_list)
                    if remediation_text:
                        _add_finding(
                            severity=sev,
                            tool="ssl_analyzer",
                            category="tls",
                            description="TLS/HTTPS hardening opportunities detected",
                            recommended_action="Apply TLS and security-header remediations and re-test",
                            remediation=remediation_text,
                            evidence_obj={"ssl": s},
                            confidence=75,
                            tags=["tls"],
                        )
                except Exception as exc:
                    _add_action("ssl_analyze", f"SSL analysis failed: {exc}", status="error")

            async def _owasp() -> None:
                if self.config.primary_goal not in {
                    PrimaryGoal.COMPREHENSIVE,
                    PrimaryGoal.VULN_DISCOVERY,
                    PrimaryGoal.API_SECURITY,
                    PrimaryGoal.INFRASTRUCTURE,
                }:
                    _add_action("web_owasp_passive", "Skipping passive OWASP checks for this goal", status="skipped")
                    return
                try:
                    from .web_owasp import web_owasp_passive

                    _add_action("web_owasp_passive", "Running passive OWASP checks")
                    o = await web_owasp_passive(target["host_with_port"])
                    evidence["web_owasp_passive"] = o
                    for f in o.get("findings", []) or []:
                        _add_finding(
                            severity=f.get("severity", "info"),
                            tool="web_owasp",
                            category="owasp_passive",
                            description=f"{f.get('name')}: {f.get('impact')}",
                            recommended_action="Apply the recommended header/cookie/CORS hardening and verify",
                            remediation=str(f.get("remediation") or ""),
                            evidence_obj={"evidence": f.get("evidence", ""), "http": o.get("http", {})},
                            confidence=70,
                            tags=["web"],
                        )
                except Exception as exc:
                    _add_action("web_owasp_passive", f"OWASP passive checks failed: {exc}", status="error")

            tasks.extend(
                [
                    asyncio.create_task(_tech()),
                    asyncio.create_task(_recon()),
                    asyncio.create_task(_ssl()),
                    asyncio.create_task(_owasp()),
                ]
            )
            await asyncio.gather(*tasks, return_exceptions=True)

        async def _run_active_bundle() -> None:
            if not _can_do_active():
                _add_action("active_bundle", "Active scanning disabled by risk tolerance", status="skipped")
                return
            tasks: List[asyncio.Task] = []

            async def _portscan() -> None:
                try:
                    from .scanner import async_port_scan

                    common_ports = _ports_for_profile()
                    _add_action("port_scan", f"Scanning TCP ports ({len(common_ports)} ports)")
                    ports = await async_port_scan(
                        target["hostname"],
                        common_ports,
                        concurrency=int(profile["scan_concurrency"]),
                        timeout=float(profile["scan_timeout"]),
                        version_detection=False,
                    )
                    evidence["port_scan"] = ports
                    open_ports = [p for p in ports if p.get("state") == "open"]
                    if open_ports:
                        _add_finding(
                            severity="info",
                            tool="scanner",
                            category="network",
                            description=f"Open TCP ports discovered: {', '.join(str(p.get('port')) for p in open_ports[:12])}{'...' if len(open_ports) > 12 else ''}",
                            recommended_action="Validate exposed services are intended, patched, and access-controlled",
                            evidence_obj={"open_ports": open_ports},
                            confidence=75,
                            tags=["network"],
                        )
                except Exception as exc:
                    _add_action("port_scan", f"Port scan failed: {exc}", status="error")

            async def _api() -> None:
                if self.config.primary_goal not in {
                    PrimaryGoal.API_SECURITY,
                    PrimaryGoal.COMPREHENSIVE,
                    PrimaryGoal.VULN_DISCOVERY,
                }:
                    _add_action("api_probe", "Skipping API probe for this goal", status="skipped")
                    return
                if self.config.risk_tolerance == RiskTolerance.LOW:
                    _add_action("api_probe", "Skipping API probe (risk=low)", status="skipped")
                    return
                try:
                    from .api import api_probe

                    aggressive = _can_do_aggressive_api()
                    _add_action(
                        "api_probe",
                        "Running API probe (aggressive mode enabled by config)" if aggressive else "Running API probe (safe mode)",
                    )
                    res = await api_probe(target["host_with_port"], protocol=target["scheme"], aggressive=aggressive)
                    evidence["api_probe"] = res
                    for f in res.get("findings", []) or []:
                        _add_finding(
                            severity=f.get("severity", "info"),
                            tool="api",
                            category=str(f.get("type") or "api"),
                            description=str(f.get("impact") or "API security issue"),
                            recommended_action="Validate the finding and implement the provided remediation",
                            remediation=str(f.get("remediation") or ""),
                            evidence_obj={"location": f.get("location"), "details": f},
                            confidence=70,
                            tags=["api"],
                        )
                except Exception as exc:
                    _add_action("api_probe", f"API probe failed: {exc}", status="error")

            async def _dirbust() -> None:
                if self.config.risk_tolerance != RiskTolerance.HIGH:
                    _add_action("dirbust", "Skipping dirbust (requires risk=high)", status="skipped")
                    return
                if self.config.stealth_level == StealthLevel.HIGH:
                    _add_action("dirbust", "Skipping dirbust due to high stealth setting", status="skipped")
                    return
                try:
                    from .dirbuster import dirbust_scan

                    _add_action("dirbust", "Brute-discovering common web paths (limited)")
                    res = await dirbust_scan(
                        target["host_with_port"],
                        concurrency=int(profile["dir_concurrency"]),
                        https=(target["scheme"] == "https"),
                        limit=int(profile.get("dir_limit") or 250),
                    )
                    evidence["dirbust"] = res
                    interesting = [r for r in (res.get("results") or []) if int(r.get("status") or 0) in (200, 204, 301, 302, 401, 403)]
                    if interesting:
                        _add_finding(
                            severity="medium",
                            tool="dirbuster",
                            category="content_discovery",
                            description=f"Interesting web paths discovered: {', '.join(str(x.get('url')) for x in interesting[:8])}{'...' if len(interesting) > 8 else ''}",
                            recommended_action="Review exposed endpoints for authz, sensitive files, and misconfigurations",
                            evidence_obj={"interesting": interesting[:25], "summary": res.get("summary")},
                            confidence=65,
                            tags=["web"],
                        )
                except Exception as exc:
                    _add_action("dirbust", f"Dirbust failed: {exc}", status="error")

            tasks.extend([asyncio.create_task(_portscan()), asyncio.create_task(_api()), asyncio.create_task(_dirbust())])
            await asyncio.gather(*tasks, return_exceptions=True)

        iterations = 0
        last_signature: Optional[str] = None
        try:
            for i in range(int(max(1, self.config.max_iterations))):
                if datetime.now(timezone.utc).timestamp() >= deadline:
                    _add_action("stop", "Time limit reached; stopping assessment", status="ok")
                    break
                iterations = i + 1
                _add_action("iteration", f"Iteration {iterations} starting")
                await _run_passive_bundle()
                await _run_active_bundle()

                # Stop early if we're not learning anything new.
                open_ports = [p.get("port") for p in (evidence.get("port_scan") or []) if p.get("state") == "open"]
                owasp_names = [f.get("name") for f in (evidence.get("web_owasp_passive") or {}).get("findings", [])]
                api_total = ((evidence.get("api_probe") or {}).get("summary") or {}).get("total_vulnerabilities")
                signature = str({
                    "open_ports": sorted([int(p) for p in open_ports if isinstance(p, int) or str(p).isdigit()]),
                    "owasp": sorted([str(x) for x in owasp_names if x]),
                    "api_total": api_total,
                    "unique_findings": len(seen_findings),
                })
                if last_signature is not None and signature == last_signature:
                    _add_action("stop", "No new signals detected; stopping early", status="ok")
                    break
                last_signature = signature
        finally:
            if ai is not None:
                try:
                    await ai.client.aclose()
                except Exception:
                    pass

        ai_summary: Optional[str] = None
        if ai is not None:
            try:
                compact = {
                    "target": target,
                    "primary_goal": self.config.primary_goal.value,
                    "risk_tolerance": self.config.risk_tolerance.value,
                    "stealth_level": self.config.stealth_level.value,
                    "engagement_policy": self.config.engagement_policy.value,
                    "counts": {"findings": len(findings), "actions": len(actions)},
                    "signals": {
                        "open_ports": [p.get("port") for p in (evidence.get("port_scan") or []) if p.get("state") == "open"],
                        "tls": (evidence.get("ssl") or {}).get("tls"),
                        "owasp": [f.get("name") for f in (evidence.get("web_owasp_passive") or {}).get("findings", [])],
                        "api_summary": (evidence.get("api_probe") or {}).get("summary"),
                    },
                }
                system_prompt = (
                    "You are a defensive security analyst. Provide prioritized, actionable remediation guidance. "
                    "Do not provide exploitation steps, payloads, or instructions for unauthorized access. "
                    "Use only the provided metadata; do not ask for source code."
                )
                user_prompt = (
                    "Given this assessment metadata, produce a short prioritized remediation plan (5-10 bullets). "
                    "Also list 3 high-signal follow-up validations (non-exploit).\n\n" + str(compact)
                )
                ai_summary = await ai.query(system_prompt=system_prompt, user_prompt=user_prompt, temperature=0.2)
                if ai_summary:
                    _add_action("ai_summary", "AI produced prioritized remediation summary")
            except Exception as exc:
                _add_action("ai_summary", f"AI summary failed: {exc}", status="error")

        end = datetime.now(timezone.utc)
        duration_minutes = max(0.0, (end - start).total_seconds() / 60.0)

        findings_by_severity = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        for f in findings:
            sev = _normalize_severity(str(f.get("severity", "info")))
            findings_by_severity[sev] = findings_by_severity.get(sev, 0) + 1

        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        findings.sort(key=lambda x: (severity_order.get(str(x.get("severity")), 5), str(x.get("timestamp", ""))))

        recommendations: List[str] = [
            "Prioritize fixes for authentication/authorization issues and exposed secrets.",
            "Apply TLS best practices and add missing security headers.",
            "Limit exposed services to required ports only; harden and patch all internet-facing services.",
            "Enable centralized logging + alerting and validate WAF/CDN rules if present.",
        ]
        if ai_summary:
            recommendations.insert(0, "Review the AI remediation summary for prioritized actions.")

        report: Dict[str, Any] = {
            "summary": {
                "target": self.config.target,
                "start_time": start.isoformat(),
                "end_time": end.isoformat(),
                "duration_minutes": round(duration_minutes, 2),
                "iterations": iterations,
                "total_findings": len(findings),
                "total_actions": len(actions),
                "primary_goal": self.config.primary_goal.value,
                "stealth_level": self.config.stealth_level.value,
                "risk_tolerance": self.config.risk_tolerance.value,
                "engagement_policy": self.config.engagement_policy.value,
            },
            "config": asdict(self.config),
            "actions": actions,
            "findings_by_severity": findings_by_severity,
            "detailed_findings": findings,
            "ai_summary": ai_summary,
            "evidence": evidence,
            "recommendations": recommendations,
        }

        return report


def run(config: AIPentestConfig) -> Dict[str, Any]:
    """Convenience wrapper used by other modules."""

    return asyncio.run(AIPentestAgent(config).execute())
